# Use a paragraphs with a shell interpreter to execute HDFS scripts to see the files that were ingested into HDFS
hdfs dfs -ls /workshop/clickstream/data
hdfs dfs -ls /workshop/clickstream/data/products
hdfs dfs -ls /workshop/clickstream/data/users

# Use paragraphs with a %hive interpreter to execute Hive database scripts

# Create a database in Hive
CREATE DATABASE IF NOT EXISTS workshop
USE workshop

# Create a users table with a schema on top of the users.tsv file in HDFS
DROP TABLE IF EXISTS users;
CREATE EXTERNAL TABLE IF NOT EXISTS users 
(swid string, birth_dt string, gender_cd string) 
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' STORED AS TEXTFILE 
LOCATION "/workshop/clickstream/data/users"

# Confirm the table was created with the data loaded by executing a select statement on the table
SELECT * FROM users limit 10

# Create a users_orc table using the users table created in previous step using a CTAS statement
# The ORC format is an Optimized Row Columnar format that speeds up the query response
DROP TABLE IF EXISTS users_orc;
CREATE TABLE IF NOT EXISTS users_orc as
SELECT * FROM users

# Confirm the table was created with the data loaded by executing a select statement on the table
SELECT * FROM users_orc limit 10

# Create a users table with a schema on top of the products.tsv file in HDFS
DROP TABLE IF EXISTS products;
CREATE EXTERNAL TABLE IF NOT EXISTS products
(url string, category string, description string) 
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' STORED AS TEXTFILE 
LOCATION "/workshop/clickstream/data/products"

# Confirm the table was created with the data loaded by executing a select statement on the table
SELECT * FROM products limit 10

# Create a products_orc table using the products table created in previous step using a CTAS statement
DROP TABLE IF EXISTS products_orc;
CREATE TABLE IF NOT EXISTS products_orc as
SELECT * FROM products

# Confirm the table was created with the data loaded by executing a select statement on the table
SELECT * FROM products_orc limit 10


## For DRUID Ingestion
CREATE EXTERNAL TABLE clickstream_events (
`__time` timestamp,
clickstream_id string,
user_session_id string,
ipaddress string,
ts string,
gender string,
bday string,
is_purchased string,
is_page_errored string,
url string,
city string,
state string,
country string
)
STORED BY 'org.apache.hadoop.hive.druid.DruidStorageHandler'
TBLPROPERTIES (
"kafka.bootstrap.servers" = "demo.cloudera.com:6667",
"kafka.topic" = "clickstream_events",
"druid.kafka.ingestion.useEarliestOffset" = "true",
"druid.kafka.ingestion.maxRowsInMemory" = "5",
"druid.kafka.ingestion.startDelay" = "PT1S",
"druid.kafka.ingestion.period" = "PT1S",
"druid.kafka.ingestion.consumer.retries" = "2"
)



