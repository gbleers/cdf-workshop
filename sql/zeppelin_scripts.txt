# Use a paragraphs with a shell interpreter to execute HDFS scripts to see the files that were ingested into HDFS
hdfs dfs -ls /workshop/clickstream/data
hdfs dfs -ls /workshop/clickstream/data/products
hdfs dfs -ls /workshop/clickstream/data/users

# Use paragraphs with a %hive interpreter to execute Hive database scripts

# CREATE A DATABASE IN HIVE
CREATE DATABASE IF NOT EXISTS WORKSHOP
USE WORKSHOP

# CREATE A USERS TABLE WITH A SCHEMA ON TOP OF THE USERS.TSV FILE IN HDFS
DROP TABLE IF EXISTS USERS
CREATE EXTERNAL TABLE IF NOT EXISTS USERS 
(SWID STRING, BIRTH_DT STRING, GENDER_CD STRING) 
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' STORED AS TEXTFILE 
LOCATION "/workshop/clickstream/data/users"

# CONFIRM THE TABLE WAS CREATED WITH THE DATA LOADED BY EXECUTING A SELECT STATEMENT ON THE TABLE
SELECT * FROM USERS LIMIT 10

# CREATE A USERS_ORC TABLE USING THE USERS TABLE CREATED IN PREVIOUS STEP USING A CTAS STATEMENT
# THE ORC FORMAT IS AN OPTIMIZED ROW COLUMNAR FORMAT THAT SPEEDS UP THE QUERY RESPONSE
DROP TABLE IF EXISTS USERS_ORC;

CREATE TABLE IF NOT EXISTS USERS_ORC AS
SELECT * FROM USERS

# CONFIRM THE TABLE WAS CREATED WITH THE DATA LOADED BY EXECUTING A SELECT STATEMENT ON THE TABLE
SELECT * FROM USERS_ORC LIMIT 10

# CREATE A USERS TABLE WITH A SCHEMA ON TOP OF THE PRODUCTS.TSV FILE IN HDFS
DROP TABLE IF EXISTS PRODUCTS;

CREATE EXTERNAL TABLE IF NOT EXISTS PRODUCTS
(URL STRING, CATEGORY STRING, DESCRIPTION STRING) 
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' STORED AS TEXTFILE 
LOCATION "/workshop/clickstream/data/products"

# CONFIRM THE TABLE WAS CREATED WITH THE DATA LOADED BY EXECUTING A SELECT STATEMENT ON THE TABLE
SELECT * FROM PRODUCTS LIMIT 10

# CREATE A PRODUCTS_ORC TABLE USING THE PRODUCTS TABLE CREATED IN PREVIOUS STEP USING A CTAS STATEMENT
DROP TABLE IF EXISTS PRODUCTS_ORC;

CREATE TABLE IF NOT EXISTS PRODUCTS_ORC AS
SELECT * FROM PRODUCTS

# CONFIRM THE TABLE WAS CREATED WITH THE DATA LOADED BY EXECUTING A SELECT STATEMENT ON THE TABLE
SELECT * FROM PRODUCTS_ORC LIMIT 10


## FOR DRUID INGESTION
CREATE EXTERNAL TABLE CLICKSTREAM_EVENTS (
`__TIME` TIMESTAMP,
CLICKSTREAM_ID STRING,
USER_SESSION_ID STRING,
IPADDRESS STRING,
TS STRING,
GENDER STRING,
BDAY STRING,
IS_PURCHASED STRING,
IS_PAGE_ERRORED STRING,
URL STRING,
CITY STRING,
STATE STRING,
COUNTRY STRING
)
STORED BY 'org.apache.hadoop.hive.druid.druidstoragehandler'
TBLPROPERTIES (
"KAFKA.BOOTSTRAP.SERVERS" = "demo.cloudera.com:6667",
"KAFKA.TOPIC" = "clickstream_events",
"DRUID.KAFKA.INGESTION.USEEARLIESTOFFSET" = "true",
"DRUID.KAFKA.INGESTION.MAXROWSINMEMORY" = "5",
"DRUID.KAFKA.INGESTION.STARTDELAY" = "PT1S",
"DRUID.KAFKA.INGESTION.PERIOD" = "PT1S",
"DRUID.KAFKA.INGESTION.CONSUMER.RETRIES" = "2"
)

# Join with other tables
SELECT 
    CSE.TS AS TS,
    CSE.USER_SESSION_ID AS USERSESSION,
    CSE.GENDER AS GENDER,
    CSE.BDAY AS BDAY,
    CSE.IS_PURCHASED AS PURCHASED,
    CSE.IS_PAGE_ERRORED AS ERROR,
    P.CATEGORY AS PRODUCT,
    P.DESC AS DESC,
    CSE.CITY AS CITY,
    CSE.STATE AS STATE
FROM CLICKSTREAM_EVENTS CSE, PRODUCTS P 
WHERE CSE.URL = P.URL LIMIT 100

